import os
import json
import logging

import mlflow

import utils.databricks_api_helper as databricks_api_helper

import utils.aws_secrets_manager_helper as aws_secrets_manager_helper
from utils.common_entities import (
    SubEnvironment,
    Environment,
    DeploymentMode,
    DatabricksMlflowStages,
)
import tempfile
import zipfile
import subprocess
import sys

logger = logging.getLogger()
logger.setLevel(logging.INFO)

os.environ["MLFLOW_TRACKING_URI"] = "databricks://src"

DEPLOYMENT_PARAMETERS = {}
SRC_REGISTRY_URI = "databricks-uc://src"
DST_REGISTRY_URI = "databricks-uc://target"

# TODO: Read mlops-common-librairies lambda layer => arn:aws:lambda:us-east-1:417854772506:layer:mlops_common_libraries:9


def init(deployment_parameters: dict) -> None:
    global DEPLOYMENT_PARAMETERS
    DEPLOYMENT_PARAMETERS = deployment_parameters

    databricks_api_helper.init(deployment_parameters)


def set_databricks_environment(region, environment, automation_environment):
    """Used to establish connection with databricks"""
    databricks_host = f"https://formulaone-{region}-{environment.lower()}-ai-workspace.cloud.databricks.com"
    os.environ["DATABRICKS_HOST"] = databricks_host
    secret_name = f"f1ai/{automation_environment.lower()}"
    secret_key = f"databricks_token_{environment.lower()}"
    databricks_token = aws_secrets_manager_helper.get_secret_value_by_key(
        secret_name=secret_name, secret_key=secret_key
    )
    os.environ["DATABRICKS_TOKEN"] = databricks_token
    logger.info("credentials received")
    mlflow.set_tracking_uri("databricks")



def _install_pip_dep(requirement, extra=None):

    logger.info("====================================")
    logger.info(requirement)
    
    base_cmd = [
        sys.executable, "-m", "pip", "install", 
        "--platform", "manylinux2014_x86_64", "--only-binary=:all:", "--no-deps" ,"-t", tempfile.gettempdir()
    ]
    if extra:
        base_cmd.extend([requirement, extra])
    else:
        base_cmd.append(requirement)

    subprocess.check_call(base_cmd)

    logger.info("====================================")


def promote_model_registration(model_name, model_version, model_source):
    """
    Promote model from a lower databricks workspace to a higher databricks workspace.

    :param model_name: Name of source model from Unity Catalog.
    :param model_version: Version of source model to be promoted.
    :param model_source: Address of registry where to save model.
    """

    logger.info("Installing libraries")

    packages_list = [
        "mlflow-skinny==3.1.1",
        "pandas==2.3.0"     
    ]

    for package in packages_list:
        _install_pip_dep(package)

    logger.info("Adding tmp to syspath")
    sys.path.insert(1, "/tmp/")

    workspace_id = DEPLOYMENT_PARAMETERS["deployment_workspace_id"]
    src_host = DEPLOYMENT_PARAMETERS["deployment_databricks_host_lower_env"]
    src_schema = DEPLOYMENT_PARAMETERS["deployment_databricks_schema_lower_env"]
    target_host = DEPLOYMENT_PARAMETERS["deployment_databricks_host"]
    target_schema = DEPLOYMENT_PARAMETERS["deployment_databricks_schema"]
    target_env = DEPLOYMENT_PARAMETERS["deployment_environment"]

    os.environ["MLFLOW_S3_UPLOAD_EXTRA_ARGS"] = json.dumps({"ServerSideEncryption": "aws:kms", "SSEKMSKeyId": DEPLOYMENT_PARAMETERS["deployment_aws_kms_arn"] })

    logger.info(f"{src_host=}")
    logger.info(f"{src_schema=}")
    logger.info(f"{target_host=}")
    logger.info(f"{target_schema=}")
    logger.info(f"{target_env=}")

    if DEPLOYMENT_PARAMETERS["deployment_environment"] == Environment.PROD:
        src_env = Environment.QA
    else:
        src_env = Environment.DEV

    user_id = DEPLOYMENT_PARAMETERS["deployment_databricks_user"]

    _create_databricks_configuration_file(
        src_host=src_host,
        src_token=_get_databricks_token(src_env),
        target_host=target_host,
        target_token=_get_databricks_token(target_env),
    )

    result = _promote_model_artifacts(
        src_model=f"{src_schema}.{model_name}",
        src_version=model_version,
        src_registry_uri=SRC_REGISTRY_URI,
        dst_model=f"{target_schema}.{model_name}",
        dst_registry_uri=DST_REGISTRY_URI,
        dst_experiment_name=f"/Users/{user_id}/{model_name}",
    )

    logger.info(result)

    return result


def _get_databricks_token(environment):
    secret_name = f"f1ai/{environment.lower()}"
    secret_key = f"databricks_token_{environment.lower()}"
    return aws_secrets_manager_helper.get_secret_value_by_key(
        secret_name=secret_name, secret_key=secret_key
    )


def _promote_model_artifacts(
    src_model,
    src_version,
    src_registry_uri,
    dst_model,
    dst_registry_uri,
    dst_experiment_name=None,
    copy_permissions=False,
    copy_stages_and_aliases=True,
    copy_lineage_tags=True,
    verbose=False,
):

    from mlflow_export_import.copy.copy_model_version import copy

    def make_tracking_uri(registry_uri):
        if not registry_uri:
            return None
        if registry_uri.startswith("databricks-uc"):
            return registry_uri.replace("databricks-uc", "databricks")
        else:
            return registry_uri

    # TODO: can we ommit dst_expirment_name?
    logger.info(
        f"#model info model: {src_model}, version: {src_version}, source: {src_registry_uri}, target: {dst_registry_uri}"
    )
    src_tracking_uri = make_tracking_uri(src_registry_uri)
    dst_tracking_uri = make_tracking_uri(dst_registry_uri)

    logger.info("Initialize copying the model to the target workspace...")    

    logger.info(f"{src_version=}")

    logger.info(f"{dst_model=}")

    logger.info(f"{dst_experiment_name=}")

    logger.info(f"{src_tracking_uri=}")

    logger.info(f"{dst_tracking_uri=}")

    logger.info(f"{src_registry_uri=}")

    logger.info(f"{dst_registry_uri=}")

    logger.info(f"{copy_permissions=}")

    logger.info(f"{copy_stages_and_aliases=}")

    logger.info(f"{copy_lineage_tags=}")

    logger.info(f"{verbose=}")

    return copy(
        src_model,
        src_version,
        dst_model,
        dst_experiment_name,
        src_tracking_uri,
        dst_tracking_uri,
        src_registry_uri,
        dst_registry_uri,
        copy_permissions,
        copy_stages_and_aliases,
        copy_lineage_tags,
        verbose,
    )


def _create_databricks_configuration_file(
    src_host, src_token, target_host, target_token
):
    logger.info("Composing cfg file...")
    content = f"""
    [src]
    host={src_host.strip()}
    token={src_token.strip()}
    [target]
    host={target_host.strip()}
    token={target_token.strip()}
    """
    config_path = "/tmp/.databrickscfg"
    os.environ["DATABRICKS_CONFIG_FILE"] = config_path

    with open(config_path, "w") as f:
        f.write(content)
        logger.info(f"Config file created at: {config_path}")

    return config_path


def get_model_registration(model_name, model_version):
    model_registration = databricks_api_helper.get_model_registration(
        model_name, model_version
    )

    if model_registration:
        return model_registration

    return None


def get_model_registration(model_name, model_version):
    model_registration = databricks_api_helper.get_model_registration(
        model_name, model_version
    )

    if model_registration:
        return model_registration

    return None


def get_latest_model_registration(model_name, stage=None):
    registered_versions = databricks_api_helper.get_latest_model_registrations(
        model_name
    )

    if not registered_versions or len(registered_versions) == 0:
        return None

    max_version = 0

    max_model_item = None

    def to_int(s):
        try:
            return int(s)
        except:
            return 0

    for model_item in registered_versions:
        if stage:
            if model_item["current_stage"] == stage:
                return model_item

        elif model_item["current_stage"] != "Archived":
            logger.info(f" model_item {model_item} ")

            current_version = to_int(model_item["version"])

            if current_version > max_version:
                max_version = current_version

                max_model_item = model_item

    return max_model_item
